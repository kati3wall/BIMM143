---
title: "BIMM143 class9"
author: "Katie Wall"
date: "1 May 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv("https://bioboot.github.io/bimm143_W18/class-material/WisconsinCancer.csv")
head(wisc.df)
```

```{r}
#how many M's
table(wisc.df$diagnosis)
```

make a numeric classification vector
```{r}
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
table(diagnosis)
```


```{r}
# Convert the features of the data: wisc.data
wisc.data <- as.matrix( wisc.df[,3:ncol(wisc.df)])
rownames(wisc.data) <- wisc.df$id
head(wisc.data)
wisc.data <- wisc.data[,-31]
head(wisc.data)
```

## Exporatory data analysis
The functions dim(), length(), grep() and sum() may be useful for answering the first 3 questions above.

**Q1**. How many observations are in this dataset?
```{r}
nrow(wisc.data)
```

**Q2**. How many variables/features in the data are suffixed with _mean?
```{r}
# return things with the word mean in them
grep("mean", colnames(wisc.data), value = TRUE)

# return the position (ie index) of things with mean in them
grep("mean", colnames(wisc.data), value = FALSE) #default

#return things the DONT have the word mean in them
grep("mean", colnames(wisc.data), value = TRUE, invert = TRUE)

length( grep("mean", colnames(wisc.data)))
```


**Q3**. How many of the observations have a malignant diagnosis?
```{r}
sum(diagnosis)
```

## Section 2 PCA
```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

demo the minus use for extracting posititons/cols/rows etc
```{r}
x <- c("barry", "chris", "mary", "chandra")
x[-c(1:3)]
```


```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale=TRUE)
```

```{r}
# Look at summary of results
summary(wisc.pr)
```

**Q4**. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
    0.4427
    
**Q5**. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
    3 PCs (count cumulative proportion)
    
**Q6**. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
   7 PCs
   
   
   ## Section 3, interpreting PCA results
```{r}
attributes(wisc.pr)
```

   
```{r}
#Create a biplot of the wisc.pr using the biplot() function.
biplot(wisc.pr)
```
**Q7**. What stands out to you about this plot? Is it easy or difficult to understand? Why?
Data is too big, it's a bad,messy plot
```{r}
# Scatter plot observations by components 1 and 2
plot( wisc.pr$x[,1], wisc.pr$x[,2] , col = diagnosis+1, 
     xlab = "PC1", ylab = "PC2")
```

**Q**8. Repeat the same for principal components 1 and 3. What do you notice about these plots?
```{r}
# Scatter plot observations by components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")
```
same coordinate on the PC1 axis, but the y axis has flipped, it was high up the y axis on pc2 and ,low on the y axis for pc3



#scree plot

##varicance explained scree plot 
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
#proportion of variance
pve <- pr.var / sum(pr.var)
```



```{r}
# Plot cumulative proportion of variance explained
plot( cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```



```{r}
#calculate variance of each component
pr.var <- wisc.pr$sdev^2



# plot varicane explained 
```

#barplot
```{r}
plot(pve , xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## Section 3 selecting numbers of clusters
hierarchail custering

```{r}
#?hclust
#?dist

#scale the wisc.data data : data.scaled
data.scaled <- scale(wisc.data)

#calculate distance matrix needed for hclust
data.dist <- dist(data.scaled)

#
wisc.hclust <- hclust(data.dist)
```

plot our hclust model tree
```{r}
plot(wisc.hclust)
abline(h=20, col="red")
wisc.hclust.clusters <- cutree(wisc.hclust, h=20)

#or
#wisc.hclust <- cutree(wisc.hclsut, k = 4)
```

```{r}
table(wisc.hclust.clusters)
```


how many M or 1 (cancer) and 0 (noncancer) are in each cluster

```{r}
table(wisc.hclust.clusters, diagnosis)
```

12 of healthy being grouped with cancer and 40 cancer grouped with healthy



Q12. Can you find a better cluster vs diagnoses match with by cutting into a different number of clusters between 2 and 10?


## section 4 k-means

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
wisc.km
```
```{r}
table(wisc.km$cluster, diagnosis)
```
```{r}
table(wisc.hclust.clusters, wisc.km$cluster)
```

## section 5 clustering PCA results
```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]))
plot(wisc.pr.hclust)
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
```
```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```

